{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf274a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bcb408",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reg=pd.read_csv('Vader Sentiment Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98b698e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>Location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39606</th>\n",
       "      <td>39606</td>\n",
       "      <td>AnimalProjectGE</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>13717</td>\n",
       "      <td>2022-03-28 19:24:13+00:00</td>\n",
       "      <td>https://twitter.com/AnimalProjectGE</td>\n",
       "      <td>What a day for #straydogs in #Zugdidi üá¨üá™ aband...</td>\n",
       "      <td>Tbilisi, Georgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.290977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49394</th>\n",
       "      <td>49394</td>\n",
       "      <td>omventure</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>11432</td>\n",
       "      <td>2022-04-17 04:52:08+00:00</td>\n",
       "      <td>https://twitter.com/omventure</td>\n",
       "      <td>\"Pain, suffering, grief‚Ä¶can be experienced by ...</td>\n",
       "      <td>A Planet Needing Our Help</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.272314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>4370</td>\n",
       "      <td>joe8Zeta7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>20059</td>\n",
       "      <td>2022-02-03 20:10:24+00:00</td>\n",
       "      <td>https://twitter.com/joe8Zeta7</td>\n",
       "      <td>Speak Out Against Plans for an Intensive Chick...</td>\n",
       "      <td>Italia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.589853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27233</th>\n",
       "      <td>27233</td>\n",
       "      <td>SilentBawse</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.9725</td>\n",
       "      <td>818</td>\n",
       "      <td>2022-07-25 05:42:59+00:00</td>\n",
       "      <td>https://twitter.com/SilentBawse</td>\n",
       "      <td>According to #AnimalRights scheme there isn't ...</td>\n",
       "      <td>Punjab/Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.365839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17641</th>\n",
       "      <td>17641</td>\n",
       "      <td>EnviroEdgeNews</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>54694</td>\n",
       "      <td>2021-03-23 18:28:24+00:00</td>\n",
       "      <td>https://twitter.com/EnviroEdgeNews</td>\n",
       "      <td>DEMAND DEFORESTATION-FREE OLYMPICS! Tokyo Olym...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.507675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>8246</td>\n",
       "      <td>Animal_Posting</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>71180</td>\n",
       "      <td>2020-11-16 16:32:12+00:00</td>\n",
       "      <td>https://twitter.com/Animal_Posting</td>\n",
       "      <td>I think #vegetarians who live according to alt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.894057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80200</th>\n",
       "      <td>80200</td>\n",
       "      <td>criticalviews20</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>60800</td>\n",
       "      <td>2021-02-06 03:19:40+00:00</td>\n",
       "      <td>https://twitter.com/criticalviews20</td>\n",
       "      <td>Truly disgusted by @VVD , \\n\\n#AnimalXXX = ü§¢üêñü§¢...</td>\n",
       "      <td>Davos, Switzerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.725126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16191</th>\n",
       "      <td>16191</td>\n",
       "      <td>aktweet20</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>7234</td>\n",
       "      <td>2022-05-24 13:46:53+00:00</td>\n",
       "      <td>https://twitter.com/aktweet20</td>\n",
       "      <td>The time for Congress to act on horse soring, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.623726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55197</th>\n",
       "      <td>55197</td>\n",
       "      <td>veganrick</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>41254</td>\n",
       "      <td>2021-07-16 03:59:18+00:00</td>\n",
       "      <td>https://twitter.com/veganrick</td>\n",
       "      <td>Endangered Elk Starve While the National Park ...</td>\n",
       "      <td>Canadaüá®üá¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.656538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78347</th>\n",
       "      <td>78347</td>\n",
       "      <td>barr3aby</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>56362</td>\n",
       "      <td>2021-03-09 16:50:35+00:00</td>\n",
       "      <td>https://twitter.com/barr3aby</td>\n",
       "      <td>Hold @Sofina_Foods and Brussels Transport acco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.309462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         username    neg    neu    pos  compound  \\\n",
       "39606       39606  AnimalProjectGE  0.253  0.648  0.099   -0.5423   \n",
       "49394       49394        omventure  0.000  0.732  0.268    0.8555   \n",
       "4370         4370        joe8Zeta7  0.000  0.709  0.291    0.7901   \n",
       "27233       27233      SilentBawse  0.357  0.607  0.036   -0.9725   \n",
       "17641       17641   EnviroEdgeNews  0.257  0.595  0.148   -0.5574   \n",
       "8246         8246   Animal_Posting  0.060  0.826  0.114    0.3400   \n",
       "80200       80200  criticalviews20  0.126  0.667  0.207    0.2960   \n",
       "16191       16191        aktweet20  0.180  0.711  0.109   -0.3612   \n",
       "55197       55197        veganrick  0.000  0.931  0.069    0.4404   \n",
       "78347       78347         barr3aby  0.161  0.654  0.185   -0.0000   \n",
       "\n",
       "       Unnamed: 0.1                       date  \\\n",
       "39606         13717  2022-03-28 19:24:13+00:00   \n",
       "49394         11432  2022-04-17 04:52:08+00:00   \n",
       "4370          20059  2022-02-03 20:10:24+00:00   \n",
       "27233           818  2022-07-25 05:42:59+00:00   \n",
       "17641         54694  2021-03-23 18:28:24+00:00   \n",
       "8246          71180  2020-11-16 16:32:12+00:00   \n",
       "80200         60800  2021-02-06 03:19:40+00:00   \n",
       "16191          7234  2022-05-24 13:46:53+00:00   \n",
       "55197         41254  2021-07-16 03:59:18+00:00   \n",
       "78347         56362  2021-03-09 16:50:35+00:00   \n",
       "\n",
       "                                      user  \\\n",
       "39606  https://twitter.com/AnimalProjectGE   \n",
       "49394        https://twitter.com/omventure   \n",
       "4370         https://twitter.com/joe8Zeta7   \n",
       "27233      https://twitter.com/SilentBawse   \n",
       "17641   https://twitter.com/EnviroEdgeNews   \n",
       "8246    https://twitter.com/Animal_Posting   \n",
       "80200  https://twitter.com/criticalviews20   \n",
       "16191        https://twitter.com/aktweet20   \n",
       "55197        https://twitter.com/veganrick   \n",
       "78347         https://twitter.com/barr3aby   \n",
       "\n",
       "                                              tweet_text  \\\n",
       "39606  What a day for #straydogs in #Zugdidi üá¨üá™ aband...   \n",
       "49394  \"Pain, suffering, grief‚Ä¶can be experienced by ...   \n",
       "4370   Speak Out Against Plans for an Intensive Chick...   \n",
       "27233  According to #AnimalRights scheme there isn't ...   \n",
       "17641  DEMAND DEFORESTATION-FREE OLYMPICS! Tokyo Olym...   \n",
       "8246   I think #vegetarians who live according to alt...   \n",
       "80200  Truly disgusted by @VVD , \\n\\n#AnimalXXX = ü§¢üêñü§¢...   \n",
       "16191  The time for Congress to act on horse soring, ...   \n",
       "55197  Endangered Elk Starve While the National Park ...   \n",
       "78347  Hold @Sofina_Foods and Brussels Transport acco...   \n",
       "\n",
       "                        Location coordinates  Unnamed: 7 Sentiment     Score  \n",
       "39606           Tbilisi, Georgia         NaN         NaN  negative  0.290977  \n",
       "49394  A Planet Needing Our Help         NaN         NaN  negative  0.272314  \n",
       "4370                      Italia         NaN         NaN   neutral  0.589853  \n",
       "27233            Punjab/Pakistan         NaN         NaN  negative  0.365839  \n",
       "17641                        NaN         NaN         NaN   neutral  0.507675  \n",
       "8246                         NaN         NaN         NaN  positive  0.894057  \n",
       "80200         Davos, Switzerland         NaN         NaN  positive  0.725126  \n",
       "16191                        NaN         NaN         NaN  positive  0.623726  \n",
       "55197                   Canadaüá®üá¶         NaN         NaN  positive  0.656538  \n",
       "78347                        NaN         NaN         NaN  negative  0.309462  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_reg.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9254288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['neg','neu','pos','compound']\n",
    "features_azure=['Score']\n",
    "target_label='Sentiment'\n",
    "target_label1='Sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b7420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 62999, Test Set : 27001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "senti_x,senti_y=csv_reg[features].values,csv_reg[target_label].values\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(senti_x, senti_y, train_size=0.7,random_state=0,stratify=senti_y)\n",
    "print('Training Set : %d, Test Set : %d \\n'%(x_train.shape[0],x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fed49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the gaussian classifier for vader sentiment analysis\n",
    "clf=RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "#Train the model\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24d48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the test data\n",
    "Y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604e3811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the vader predictive model is: 0.4736861597718603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy Score of the vader predictive model is:',accuracy_score(Y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08da064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : 62999, Test Set : 27001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "azure_x=csv_reg[features_azure].values\n",
    "azure_y=csv_reg[target_label1].values\n",
    "x_train_azure,x_test_azure,y_train_azure,y_test_azure=train_test_split(azure_x,azure_y,train_size=0.7,random_state=0,stratify=senti_y)\n",
    "print('Training Set : %d, Test Set : %d \\n'%(x_train_azure.shape[0],x_test_azure.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d9b9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the gaussian classifier for vader sentiment analysis\n",
    "clfazure=RandomForestClassifier(n_estimators=300)\n",
    "\n",
    "#Train the Model\n",
    "clfazure.fit(x_train_azure,y_train_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3abd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Pred_azure=clfazure.predict(x_test_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09229234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the Azure predictive model is: 1.0\n",
      "\n",
      " Overall precision score of the model is: 1.0\n",
      "\n",
      " Overall recall score of the model is: 1.0\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     10440\n",
      "     neutral       1.00      1.00      1.00      6510\n",
      "    positive       1.00      1.00      1.00     10051\n",
      "\n",
      "    accuracy                           1.00     27001\n",
      "   macro avg       1.00      1.00      1.00     27001\n",
      "weighted avg       1.00      1.00      1.00     27001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "print('Accuracy Score of the Azure predictive model is:',accuracy_score(y_test_azure,Y_Pred_azure))\n",
    "print('\\n Overall precision score of the model is:',precision_score(y_test_azure,Y_Pred_azure,average='macro'))\n",
    "print('\\n Overall recall score of the model is:',recall_score(y_test_azure,Y_Pred_azure,average='macro'))\n",
    "\n",
    "print('\\n', classification_report(y_test_azure,Y_Pred_azure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf64a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the vader predictive model is: 0.4736861597718603\n",
      "\n",
      " Overall precision score of the model is: 0.44271851470876705\n",
      "\n",
      " Overall recall score of the model is: 0.4543617119106747\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.50      0.52     11196\n",
      "     neutral       0.22      0.39      0.28      3653\n",
      "    positive       0.57      0.47      0.52     12152\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.44      0.45      0.44     27001\n",
      "weighted avg       0.51      0.47      0.49     27001\n",
      "\n",
      "\n",
      " [[5646 2351 3199]\n",
      " [1115 1415 1123]\n",
      " [3679 2744 5729]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Accuracy Score of the vader predictive model is:',accuracy_score(Y_pred,y_test))\n",
    "print('\\n Overall precision score of the model is:',precision_score(Y_pred,y_test,average='macro'))\n",
    "print('\\n Overall recall score of the model is:',recall_score(Y_pred,y_test,average='macro'))\n",
    "\n",
    "print('\\n', classification_report(Y_pred,y_test))\n",
    "\n",
    "mcm_vader=confusion_matrix(Y_pred,y_test)\n",
    "\n",
    "print('\\n',mcm_vader)\n",
    "\n",
    "vader_classes=['positive','negative','neutral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804a515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(mcm_vader, interpolation=\"nearest\",cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks=np.arange(len(vader_classes))\n",
    "plt.xticks(tick_marks,vader_classes,rotation=45)\n",
    "plt.yticks(tick_marks,vader_classes)\n",
    "plt.xlabel(\"Predicted Sentiments\")\n",
    "plt.ylabel(\"Actual Sentiments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ab5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisvader=LogisticRegression()\n",
    "\n",
    "logisvader.fit(x_train,y_train)\n",
    "\n",
    "Y_pred_vad_log=logisvader.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b648d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the vader Logistic predictive model is: 0.4306136809747787\n",
      "\n",
      " Overall precision score of the model is: 0.3790631699151696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Overall recall score of the model is: 0.28808525150769154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.44      0.47     11892\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "    positive       0.63      0.42      0.50     15109\n",
      "\n",
      "    accuracy                           0.43     27001\n",
      "   macro avg       0.38      0.29      0.33     27001\n",
      "weighted avg       0.58      0.43      0.49     27001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of the vader Logistic predictive model is:',accuracy_score(Y_pred_vad_log,y_test))\n",
    "print('\\n Overall precision score of the model is:',precision_score(Y_pred_vad_log,y_test,average='macro'))\n",
    "print('\\n Overall recall score of the model is:',recall_score(Y_pred_vad_log,y_test,average='macro'))\n",
    "\n",
    "print('\\n', classification_report(Y_pred_vad_log,y_test))\n",
    "\n",
    "mcm_vader=confusion_matrix(Y_pred_vad_log,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef321bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisazure=LogisticRegression()\n",
    "logisazure.fit(x_train_azure,y_train_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "025a5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_azure_log=logisazure.predict(x_test_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abbd7e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the Azure Logistic predictive model is: 0.9957038628198955\n",
      "\n",
      " Overall precision score of the model is: 0.9962419248041883\n",
      "\n",
      " Overall recall score of the model is: 0.9941644028574302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.44      0.47     11892\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "    positive       0.63      0.42      0.50     15109\n",
      "\n",
      "    accuracy                           0.43     27001\n",
      "   macro avg       0.38      0.29      0.33     27001\n",
      "weighted avg       0.58      0.43      0.49     27001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of the Azure Logistic predictive model is:',accuracy_score(y_pred_azure_log,y_test_azure))\n",
    "print('\\n Overall precision score of the model is:',precision_score(y_pred_azure_log,y_test_azure,average='macro'))\n",
    "print('\\n Overall recall score of the model is:',recall_score(y_pred_azure_log,y_test_azure,average='macro'))\n",
    "\n",
    "print('\\n', classification_report(Y_pred_vad_log,y_test_azure))\n",
    "\n",
    "mcm_vader=confusion_matrix(Y_pred_vad_log,y_test_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a6172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
